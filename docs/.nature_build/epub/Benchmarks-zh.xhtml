<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <meta charset="utf-8" />
    <title>性能测试</title>
    <link rel="stylesheet" href="_static/epub.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> 
  </head><body>

    <div class="document">
      <div class="documentwrapper">
          <div class="body" role="main">
            
  <div class="section" id="id1">
<h1>性能测试</h1>
<p>作为C++的Http应用框架，性能应该是关注的重点之一，本节介绍Drogon的简单测试和成绩；</p>
<div class="section" id="id2">
<h2>测试环境</h2>
<blockquote>
<div><ul class="simple">
<li><p>系统是Linux CentOS 7.4；</p></li>
<li><p>设备是Dell服务器，CPU是两颗Intel(R) Xeon(R) CPU E5-2670 &#64; 2.60GHz，16核32线程；</p></li>
<li><p>内存64GB；</p></li>
<li><p>gcc版本7.3.0；</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="id3">
<h2>测试方案和结果</h2>
<p>我们只是为了测试drogon框架的性能，因而要尽量简化controller的处理，我们只做了一个HttpSimpleController，注册到*/benchmark*路径上。controller对任何请求都返回*&lt;p&gt;Hello, world!&lt;/p&gt;*。设置drogon线程数为16。handler函数的代码如下, 你可以在*drogon/examples/benchmark*目录找到这些源码：</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span> <span class="n">BenchmarkCtrl</span><span class="o">::</span><span class="n">asyncHandleHttpRequest</span><span class="p">(</span><span class="k">const</span> <span class="n">HttpRequestPtr</span> <span class="o">&amp;</span><span class="n">req</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">function</span><span class="o">&lt;</span><span class="kt">void</span> <span class="p">(</span><span class="k">const</span> <span class="n">HttpResponsePtr</span> <span class="o">&amp;</span><span class="p">)</span><span class="o">&gt;</span> <span class="o">&amp;&amp;</span><span class="n">callback</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">//write your application logic here</span>
    <span class="k">auto</span> <span class="n">resp</span> <span class="o">=</span> <span class="n">HttpResponse</span><span class="o">::</span><span class="n">newHttpResponse</span><span class="p">();</span>
    <span class="n">resp</span><span class="o">-&gt;</span><span class="n">setBody</span><span class="p">(</span><span class="s">&quot;&lt;p&gt;Hello, world!&lt;/p&gt;&quot;</span><span class="p">);</span>
    <span class="n">resp</span><span class="o">-&gt;</span><span class="n">setExpiredTime</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
    <span class="n">callback</span><span class="p">(</span><span class="n">resp</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>作为对比，我选取了nginx来做对比测试，使用nginx+module源码编译的方式，写了一个hello_world_module，测试时nginx的worker_processes参数设为16。</p>
<p>测试工具是一个性能不错的HTTP压力测试工具*httpress*。</p>
<p>我们调整httpress的参数，每组参数测试五次，记录每秒处理请求数的最大值和最小值。测试结果如下表：</p>
<table class="docutils">
<colgroup>
<col style="width: 30%" />
<col style="width: 47%" />
<col style="width: 11%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>命令行</p></th>
<th class="head"><p>说明</p></th>
<th class="head"><p>Drogon(千QPS)</p></th>
<th class="head"><p>nginx(千QPS)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>httpress -c 100 -n 1000000 -t 16 -k -q URL</p></td>
<td><p>100连接，100万请求，16线程，Keep-Alive</p></td>
<td><p>561/552</p></td>
<td><p>330/329</p></td>
</tr>
<tr class="row-odd"><td><p>httpress -c 100 -n 1000000 -t 12 -q URL</p></td>
<td><p>100连接，100万请求，12线程，一次请求一次连接</p></td>
<td><p>140/135</p></td>
<td><p>31/49</p></td>
</tr>
<tr class="row-even"><td><p>httpress -c 1000 -n 1000000 -t 16 -k -q URL</p></td>
<td><p>1000连接，100万请求，16线程，Keep-Alive</p></td>
<td><p>573/565</p></td>
<td><p>333/327</p></td>
</tr>
<tr class="row-odd"><td><p>httpress -c 1000 -n 1000000 -t 16 -q URL</p></td>
<td><p>1000连接，100万请求，16线程，一次请求一次连接</p></td>
<td><p>155/143</p></td>
<td><p>52/50</p></td>
</tr>
<tr class="row-even"><td><p>httpress -c 10000 -n 4000000 -t 16 -k -q URL</p></td>
<td><p>10000连接，400万请求，16线程，Keep-Alive</p></td>
<td><p>512/508</p></td>
<td><p>316/314</p></td>
</tr>
<tr class="row-odd"><td><p>httpress -c 10000 -n 1000000 -t 16 -q URL</p></td>
<td><p>10000连接，100万请求，16线程，一次请求一次连接</p></td>
<td><p>143/141</p></td>
<td><p>43/40</p></td>
</tr>
</tbody>
</table>
<p>可以看到，在客户端使用Keep-Alive选项，在一个连接可以发送多个请求的情况下，drogon每秒可以处理50多万次请求，这个成绩是相当不错的。每次请求都发起一次连接的情况下，CPU会消耗在TCP建立和断开等环节，吞吐量会下降至每秒14万次请求，这也是正常的。drogon对比nginx的成绩处于明显优势，也许是由于nginx配置不当未能发挥它的最大吞吐量，如果哪位高手做了更好的测试，欢迎指正。</p>
<p>下图是某一次测试的截图：</p>
<p>测试截图</p>
</div>
</div>


          </div>
      </div>
      <div class="clearer"></div>
    </div>
  </body>
</html>